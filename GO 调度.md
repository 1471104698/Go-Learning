# GO 调度



## 用户线程和OS线程、CPU 的关系

首先我们需要明白，在 Linux 中线程的概念实际上就是轻量级进程，我们把它叫做 OS 线程/ 内核线程

对于 CPU 来说，它只能调度的是 OS 线程，并不能感知到用户线程的存在，因此，CPU 执行的是什么任务，具体看 OS 线程

CPU 跟 OS 线程绑定，OS 线程能够跟用户线程进行绑定，相当于 OS 线程是 CPU 和 用户线程沟通的桥梁

OS 线程和用户线程绑定相当于是 用户线程将任务交给 OS 线程去执行，CPU 和 OS 线程绑定相当于是 CPU 去执行 OS 线程内的任务，换句话说，在 CPU 看来它虽然是在执行 OS 线程的任务，但是实际上 OS 线程的任务是用户线程的，即它实际上是在执行用户线程的任务，不过它感知不到



> #### 例子说明

```
游戏里有一座城池，CPU 是城池内的玩家，负责领取并完成任务，OS 线程负责从城池外部接收别人的委托，用户线程是城池外的人向城池内的人提供委托（这里的委托就是我们让线程执行的任务）

OS 线程会接收城池外的用户线程的委托，将委托放在自己这里，然后 CPU 来 OS 线程这里领取委托去完成
我们可以理解为每个任务内部都是一行行的有顺序的二进制指令，CPU 根据顺序去执行这些指令，执行完全部指令这个任务也就完成了
```

在这里 CPU 是不知道任务是哪个用户线程发出的，它能看到的只有 OS 线程，或者说 CPU 感知不到用户线程的存在



> #### 关于 OS 线程作用的个人推测的一个点（只是有可能包含这一点）

个人感觉 CPU 直接调度 OS 线程的话是为了适配不同类型的用户线程，OS 线程类似于一个抽象接口，CPU 调度的就是这个统一的接口，它并不关心用户线程是 Java 线程还是 Go 协程，只要这些用户线程适配 OS 线程能够跟 OS 线程绑定即可，这样对于 CPU 来说也是屏蔽了不同用户线程实现的差异



## 调度方式

目前线程调度模型存在三种：

1. 用户级线程模型
2. 内核级线程模型
3. 两级线程模型



> ####  用户级线程模型 N：1

一个 OS 线程对应 N 个用户线程，所有的用户线程都由该 OS 线程控制，一个 CPU 核心 只需要执行同一个 OS 线程，而该 OS 线程具体的执行内容由和它当前绑定的用户线程决定

一个用户进程里无论存在多少个用户线程，它始终都是只一个 OS 线程进行绑定，线程的创建和销毁都是由用户自己的线程库来实现的（比如 Java 有自己的线程库，它如果使用 N:1 模型的话那么这些用户线程创建和销毁都是它自己来管理），**无需使用系统调用，不需要涉及到内核**，并且线程上下文切换也只会涉及到用户线程，不会涉及到内核，减少成本

问题在于，CPU 每次只能跟一个用户进程进行绑定，它的眼里实际上只有与用户进程绑定的那个 OS 线程，而没有什么用户线程，它至始至终都是在执行那个 OS 线程，而一旦与 OS 线程绑定的用户线程进入阻塞状态，那么就会导致整个用户进程的所有线程都被阻塞，因为用户进程内的线程调度是不存在 CPU 中断的，因此此时整个用户进程被挂起，与之绑定的 OS 线程也陷入阻塞状态，那么会导致用户进程其他线程无法执行，CPU 中断/轮转 也会放弃该 OS 线程，进行内核态上下文切换去执行其他的 OS 线程

```
因此，后面大多的协程库都是在阻塞的点实现非阻塞，在阻塞时用户线程主动让出，让其他用户线程跟OS线程进行绑定，这样可以避免用户进程阻塞，导致OS线程阻塞，导致 CPU 发生内核上下文切换，可以继续执行
```



优点：上下文切换的成本低，一般情况下，减少内核上下文切换

缺点：无法利用 CPU 多核，一个用户进程多个任务并发执行也只能利用一个 CPU 核心



> #### 内核级线程模型 1：1

一个 OS 线程对应一个用户线程

一个用户进程内多个用户线程，每个用户线程都绑定一个 OS 线程，这种的用户线程基本就是对 OS 线程的封装，比如 Java 的 Thread，每创建一个线程实际上就是创建一个 OS 线程，返回得到的 Thread 是对这个 OS 线程的封装。线程的创建和销毁都是交给内核来完成，成本比较高

这种模型由于一个用户进程对应多个 OS 线程，CPU 可以直接借助操作系统来完成对 OS 线程的调度，来完成 OS 线程的快速切换，并且在多核CPU上，可以同时执行用户进程中与之绑定的多个OS线程，真正达到并行计算的优点



优点：利用 CPU 多核，一次能够并行执行多个线程，并且不存在用户级线程模型一个线程阻塞就导致整个用户进程阻塞的问题

缺点：线程创建和销毁、线程上下文切换等都依赖内核，成本高，每次切换用户线程实际上就是在切换 OS 线程

【目前 Java 调度模型使用的就是这一种】



> ####  两级线程模型 N：M

N 个 OS 线程对应 M 个用户线程

这个模型集合了上面两个模型的优点：

1、首先区别于用户级线程模型，用户进程中的每个用户线程都可以跟一个 OS 线程进程绑定，这点类似于内核级线程模型

2、其次区别于内核级线程模型，用户进程中的多个用户线程可以绑定同一个 OS 线程，当某个 OS 线程因为阻塞而被 CPU 停止调度时，OS 线程可以跟其他的用户线程进行绑定，然后继续等待 CPU 进行调度

它这种模型是比较灵活的，相比 N:1 模型，OS 线程阻塞了也不会导致整个用户进程阻塞，因为它存在多个 OS 线程，一个 OS 线程阻塞了也可能去调度其他的 OS  线程，同时它阻塞的 OS 线程还可以再去绑定其他未阻塞的用户线程；相比 1:1 模型，多个用户线程可以绑定一个 OS 线程，减少了线程的上下文切换以及创建和销毁的成本

```
比如存在 CPU 核心 1 2，OS线程 1 2，用户线程 1 2 3 4。 CPU 核心 1 目前跟 OS 线程 1 绑定，CPU 核心 2 目前跟 OS 线程 2 绑定，我将 用户线程 1 2 分配给 OS线程 1,将用户线程 3 4 分配给 OS 线程 2，这样既能够利用到 多核 CPU，如果用户线程1 停止执行了，那么只需要将 OS 线程1 跟 用户线程2 进行绑定即可，CPU 

核心 1 和 OS 线程 1 之间并不需要进行解绑，即不需要发生 OS 线程的上下文切换
```

【目前 GO 调度模型基于两级模型来实现的，并不完全一样】



## GO 调度模型-GMP

> #### GMP 概述

一般情况下，每一个 OS 线程都有固定大小的内存块来作为栈（一般是 2MB），存放当前正在调用或挂起的函数的变量等信息，这个栈的大小有时很大又有时很小，对于一般情况下的线程来说它有很大一部分空间是浪费的，而对于执行深度嵌套的递归的线程来说又显得太小了

因此 GO 实现了自己的 【线程】- goroutine

goroutine 在创建时会分配固定大小为 2KB 的栈，不过它采用**动态扩容/收缩**的方式，随着任务执行按需扩容，最大可达到 1GB（64 位机器最大是 1G，32 位机器最大是 256M），由 GO 自己的调度器 **Go Scheduler**  来完成调度，并且 go GC 还会周期性的对 goroutine 不使用的栈内存进行清理，收缩栈空间。



G：

​	goroutine，内部记录 goroutine 的一些信息，比如阻塞当前 goroutine 的 channel

M：

​	machine，可以理解为 OS 线程的抽象

P：

​	processor，可以理解为 CPU 核心的抽象，P 的最大数量为 CPU 核心数，**但实际上在运行的时候 P 跟  CPU 核心并没有任何关联，可以理解为 P 只是用来限制并行运行的 M 的个数的**，有多少个 P 就能够同时并行运行多少个 M，通过 P 来限制 M 的并行运行个数。



**一个 P 同一时间只能跟一个 M 进行绑定，一个 M 同一时间只能执行一个 G**

**M 和 P、P 和 G、M 和 G 之间没有固定的绑定关系，可以随时解绑，也可以随时绑定**

任何用户线程都是需要交给 OS 线程来执行的，go 也不例外，不过 go 不是直接将 G 跟 M  绑定的，而是使用 P 作为中介来建立 G 和 M 是联系。

G 在创建的时候会找到一个 P 进入到该 P 所管理的 G 队列中，新创建的 M 或者游离中（未绑定 P） 的 M 会找到一个游离中的 P，然后执行 schedule() 函数，在该函数中会从 P 的 G 队列中找到一个可执行的 G 来执行。

在 G 的角度，P 就是 CPU 核心，而 M 如果想要执行 G 被 CPU 核心调用的话，那么就需要先去找一个 P 进行绑定，以此来限制 M 的并行计算个数

M 并不会保存 G 的信息，当 M 由于某种原因不再执行 G 时，那么此时寄存器等的信息保存在 G 中，即 M 不会去记录上一次执行的是哪个 G，当 M 要执行某个 G 的时候，如果这个 G 是之前已经执行过一部分的了，那么 M 会从这个 G 中读取这个 G 上一次执行的状态信息，然后继续执行。**这是 G 能够在不同的 M 上执行的基础**



> #### M的状态

M并没有像G和P一样的状态标记, 但可以认为一个M有以下的状态:

- 自旋中(spinning): M正在从运行队列获取G, 这时候M会拥有一个P
- 执行go代码中: M正在执行go代码, 这时候M会拥有一个P
- 执行原生代码中: M正在执行原生代码或者阻塞的syscall, 这时M并不拥有P
- 休眠中: M发现无待运行的G时会进入休眠, 并添加到空闲M链表中, 这时M并不拥有P

自旋中(spinning)这个状态非常重要, 是否需要唤醒或者创建新的M取决于当前自旋中的M的数量.



> #### GMP 三种队列

GMP 中存在三种类型的队列：

1. runnext：P 私有，它只能存储一个 G，每一个新加入的 G 都会先进入到该 P 中的 runnext，如果 runnext 中已经有 G 了，那么将这个 G 挤出，然后入队，runnext 中的 G 是与该 P 绑定的 M 会去优先执行的
2.  local 队列：本地队列，P 私有，它用来存储跟 P 绑定的 G，当 runnext 中的 G 被挤出时，那么它会进入到 local 队列中，如果 local 队列已满，那么 G 会存放到 global 队列中
3. global 队列：全局队列，所有 P 共享，当 P 某个 local 队列已满，那么会将新接收的 G 放入到 global 队列中



M 查找 G 的过程：

- 先从 P 的 runnext 中找
- 再从 P 的 local 队列中找
- 再从全局队列中找

（期间会存在窃取别的 P 的 G 的情况，这里就不讲了）



> #### P 的作用

在 GO 1.0 版本的时候是只有 M 和 G，不存在 P，此时有以下问题：

1、只有一个 global 队列，这样的话所有的 M 都是直接从这个全局队列中获取，这样的话需要一个全局锁，频繁的加锁解锁性能低。而有了 P，每个 M 绑定的 P 上的队列一次只有一个 M 去扫描，避免了加锁和解锁的操作

2、难以控制并行执行的 M 的数量，而有了 P，能够利用 P 来控制 M 并行运行的个数

